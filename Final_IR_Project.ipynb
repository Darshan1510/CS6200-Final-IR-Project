{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Darshan1510/CS6200-Final-IR-Project/blob/master/Final_IR_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install the Kaggle Library\n",
        "Install Kaggle Library so you are able to seemlessly use the datasets available.\n",
        "\n"
      ],
      "metadata": {
        "id": "8rtgj0nMrcci"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EPBvnfr2fqoT"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install kaggle\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Upload Kaggle API key using the following code:\n",
        "You need to create a API token so you're able to directly download datasets. To find your API token (a downloaded json file go to kaggle.com -> login -> go to your account -> API -> Create new token.\n",
        "\n"
      ],
      "metadata": {
        "id": "uQ5NkU4Arj_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload your Kaggle API key\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move the API key\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "JZHmhGIsrnwO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "8804c940-7a73-4631-c37b-0dab0fd79285"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8a112cad-98b1-44e1-b7e1-0cf8ce70b69b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8a112cad-98b1-44e1-b7e1-0cf8ce70b69b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query Processing\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9IITkqmjpkqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Dataset - I'm using the IMDB movies dataset so to get example queries of movie name and movie casts and crew to prevent bias in query annotation and formation. This will download the dataset to be used in your colab content folder."
      ],
      "metadata": {
        "id": "xKqYzBzVp5g4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!kaggle datasets download -d ashpalsingh1525/imdb-movies-dataset\n",
        "#!unzip imdb-movies-dataset.zip\n",
        "!unzip /content/imdb-movies-dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHeeueRWfr91",
        "outputId": "748dbf55-be84-47a2-d5b3-5caa680eceae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/imdb-movies-dataset.zip, /content/imdb-movies-dataset.zip.zip or /content/imdb-movies-dataset.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/imdb_movies.csv.zip\n",
        "#github_dataset_url = 'https://github.com/LearnDataSci/articles/blob/master/Python%20Pandas%20Tutorial%20A%20Complete%20Introduction%20for%20Beginners/IMDB-Movie-Data.csv'\n",
        "local_dataset_url = '/content/imdb_movies.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlc4lHKSv0qo",
        "outputId": "781e81de-b37d-4fd6-d5ad-c303f72dadc2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/imdb_movies.csv.zip, /content/imdb_movies.csv.zip.zip or /content/imdb_movies.csv.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use downloaded imdb movies dataset to retrieve movie names and cast and crew names for query expansion."
      ],
      "metadata": {
        "id": "Vu0BbHjHqI0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "\n",
        "def get_movies(dataset_url, num):\n",
        "  # Load the dataset\n",
        "  df = pd.read_csv(dataset_url)\n",
        "  # Randomly choose 5 movies\n",
        "  selected_movies = df['names'].sample(num)\n",
        "  return selected_movies\n",
        "\n",
        "\n",
        "def get_crew_details(dataset_url, num):\n",
        "  # Load the dataset\n",
        "  df = pd.read_csv(dataset_url)\n",
        "  # Display 5 entries from the 'crew' column\n",
        "  crew_lists = df['crew'].str.split(', ')\n",
        "\n",
        "  # Create a list of valid crew members (excluding those with \"(voice)\")\n",
        "  valid_crew = [crew.strip() for sublist in crew_lists.dropna() for crew in sublist if \"(voice)\" not in str(crew) and len(crew.split()) >= 2]\n",
        "\n",
        "  # Randomly choose 5 crew members from the valid list\n",
        "  random_crew_members = random.sample(valid_crew, num)\n",
        "  return random_crew_members"
      ],
      "metadata": {
        "id": "6ozUQD4_tQXj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO: set list of movies and crew based on output of the above code\n",
        "\n",
        "# set the number of parameters\n",
        "num = 10\n",
        "\n",
        "dataset_url = local_dataset_url\n",
        "selected_movies = get_movies(dataset_url, num)\n",
        "selected_crew_members = get_crew_details(dataset_url, num)\n",
        "\n",
        "print(\"Selected Movies:\")\n",
        "for movie in selected_movies:\n",
        "    print(movie)\n",
        "\n",
        "print(\"\\nSelected Crew:\")\n",
        "for crew_member in selected_crew_members:\n",
        "    print(crew_member)\n",
        "\n",
        "# selected_movies = [\"Letters to Juliet\", \"Scrooge: A Christmas Carol\", \"The Tower\", \"Back to the Future Part II\", \"Love Affair\", \"Mean Girls 2\"]\n",
        "# selected_crew_members = [\"Dougray Scott\", \"Nathaniel Parker\", \"Charlie Hunnam\", \"Michael Sheen\"]"
      ],
      "metadata": {
        "id": "wC0T8q0ZvzTW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "0e149d13-7fcd-4278-baf7-7e43bdb1ab10"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-8fc8e0a59fc6>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdataset_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_dataset_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mselected_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_movies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mselected_crew_members\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_crew_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-6ca003b731f6>\u001b[0m in \u001b[0;36mget_movies\u001b[0;34m(dataset_url, num)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_movies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;31m# Randomly choose 5 movies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mselected_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/imdb_movies.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query Expansion\n",
        "\n",
        "Pass expanded queries into image icrawler"
      ],
      "metadata": {
        "id": "rsZa5-66pozm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imdbpy"
      ],
      "metadata": {
        "id": "kwRLinfcUQKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imdb import IMDb\n",
        "\n",
        "# Creating an instance of the IMDb class\n",
        "ia = IMDb()\n",
        "\n",
        "# Function to get actor data\n",
        "def get_person_data(name):\n",
        "    # Searching for the actor\n",
        "    people = ia.search_person(name)\n",
        "\n",
        "    # Assuming the first search result is the correct one\n",
        "    person = people[0]\n",
        "    ia.update(person, info=['filmography'])\n",
        "\n",
        "    # Formatting the filmography\n",
        "    filmography = person.get('filmography')\n",
        "    formatted_filmography = {}\n",
        "    for role in filmography:\n",
        "        formatted_role = []\n",
        "        for movie in filmography[role]:\n",
        "            movie_title = movie.get('title', 'Unknown Title')\n",
        "            movie_year = movie.get('year', 'Unknown Year')\n",
        "            formatted_role.append(f\"{movie_title} ({movie_year})\")\n",
        "        formatted_filmography[role] = formatted_role\n",
        "\n",
        "    # Actor data\n",
        "    person_data = {\n",
        "        'name': person['name'],\n",
        "        'headshot': person.get('full-size headshot'),\n",
        "        'filmography': formatted_filmography\n",
        "    }\n",
        "\n",
        "    return person_data\n",
        "\n",
        "\n",
        "def get_movie_data(movie_title):\n",
        "    movies = ia.search_movie(movie_title)\n",
        "\n",
        "    movie = next((mv for mv in movies if mv['title'].lower() == movie_title.lower()), None)\n",
        "    if movie:\n",
        "        ia.update(movie, info='main')\n",
        "        # Extracting relevant information\n",
        "        data = {\n",
        "            'Title': movie.get('title'),\n",
        "            'Year': movie.get('year'),\n",
        "            'Genre': movie.get('genres'),\n",
        "            'Plot': movie.get('plot outline'),\n",
        "            'Director': [director['name'] for director in movie.get('directors', [])],\n",
        "            'Cast': [actor['name'] for actor in movie.get('cast', [])],\n",
        "            'Rating': movie.get('rating'),\n",
        "            'Runtime': movie.get('runtime', [])[0] if movie.get('runtime') else None\n",
        "        }\n",
        "        return data\n",
        "    else:\n",
        "        return f\"No movie found with the title '{movie_title}'.\""
      ],
      "metadata": {
        "id": "rcHCp2MnUMZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## find queries\n",
        "def find_movies_by_director(director_name):\n",
        "    # Search for the director\n",
        "    people = ia.search_person(director_name)\n",
        "\n",
        "    for person in people:\n",
        "        if person['name'].lower() == director_name.lower():\n",
        "            # Get director's filmography\n",
        "            ia.update(person)\n",
        "            filmography = person.get('director', [])\n",
        "\n",
        "            for movie in filmography:\n",
        "                print(f\"Title: {movie.get('title')}, Year: {movie.get('year')}\")\n",
        "            break\n",
        "\n",
        "def find_movies_by_actor(actor_name):\n",
        "  # Search for the actor\n",
        "  people = ia.search_person(actor_name)\n",
        "\n",
        "  for person in people:\n",
        "    if person['name'].lower() == actor_name.lower():\n",
        "      # Get actor's filmography\n",
        "      ia.update(person)\n",
        "      filmography = person.get('actor',[])\n",
        "\n",
        "      for movie in filmography:\n",
        "        print(f\"Title: {movie.get('title')}, Year: {movie.get('year')}\")\n",
        "      break\n",
        "\n",
        "def find_cast_by_movie(movie_name):\n",
        "  # Search for the movie\n",
        "  movies = ia.search_movie(movie_name)\n",
        "  movie = ia.get_movie(movies[0].movieID)\n",
        "  #for director in movie['directors']:\n",
        "  #  print(f\"Director: {director['name']}, Movie: {movie}\")\n",
        "  for castMember in movie['cast'][:10]:\n",
        "    print(f\"Cast Member: {castMember['name']}, Role: {castMember.currentRole}\")\n"
      ],
      "metadata": {
        "id": "qSiXN9nBz4Xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##TODO: Add query expansion code here.\n",
        "def expand_movie_query(movie_name):\n",
        "  movies = ia.search_movie(movie_name)\n",
        "  movie = ia.get_movie(movies[0].movieID)\n",
        "  expandedQuery = movie_name\n",
        "  if 'directors' in movie.keys():\n",
        "    for director in movie['directors']:\n",
        "      expandedQuery = expandedQuery + \" + \" + director['name']\n",
        "      # print(f\"Director: {director['name']}, Movie: {movie}\")\n",
        "  for castMember in movie['cast'][:3]:\n",
        "    expandedQuery = expandedQuery + \" + \" + str(castMember['name']) + \" + \" + str(castMember.currentRole)\n",
        "    # print(f\"Cast Member: {castMember['name']}, Role: {castMember.currentRole}\")\n",
        "  return expandedQuery\n",
        "\n",
        "def expand_person_query(person_name):\n",
        "  # Search for the actor\n",
        "  people = ia.search_person(person_name)\n",
        "  expandedQuery = person_name\n",
        "  for person in people:\n",
        "    if person['name'].lower() == person_name.lower():\n",
        "      # Get actor's filmography\n",
        "      ia.update(person)\n",
        "      filmography = person.get('actor',[])\n",
        "\n",
        "      for movie in filmography[:5]:\n",
        "        expandedQuery = expandedQuery + \" + \" + str(movie.get('title'))\n",
        "        # print(f\"Title: {movie.get('title')}, Year: {movie.get('year')}\")\n",
        "      break\n",
        "  return expandedQuery\n"
      ],
      "metadata": {
        "id": "RDghaUdnuUu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO: Change to the list of 10 expanded randomly picked movies or actors\n",
        "movies_expanded = []\n",
        "actors_expanded = []\n",
        "\n",
        "for movie in selected_movies:\n",
        "  expanded_queries = expand_movie_query(movie)\n",
        "  movies_expanded.append(expanded_queries)\n",
        "\n",
        "for crew in selected_crew_members:\n",
        "  expanded_queries = expand_person_query(crew)\n",
        "  if expanded_queries != crew:\n",
        "    actors_expanded.append(expanded_queries)\n",
        "\n",
        "# movies_expanded =[\"Letters to Juliet + Gary Winick + Amanda Seyfried + Sophie + Marcia DeBonis + Lorraine + Gael Garc√≠a Bernal + Victor\", \"Scrooge: A Christmas Carol + Stephen Donnelly + Luke Evans + Scrooge + Olivia Colman + Past + Jessie Buckley + Isabel Fezziwig\", \"The Tower + Gemma Whelan + DS Sarah Collins + Emmett J Scanlan + Inspector Kieran Shaw + Tahirah Sharif + PC Lizzie Adama\", \"Back to the Future Part II + Michael J. Fox + Marty McFly / Marty McFly Jr. / Marlene McFly + Christopher Lloyd + Dr. Emmett Brown + Lea Thompson + Lorraine\", \"Love Affair + Warren Beatty + Mike Gambril + Annette Bening + Terry McKay + Katharine Hepburn + Ginny\", \"Mean Girls 2 + Meaghan Martin + Johanna 'Jo' Mitchell + Donn Lamkin + Sidney Hanover + Linden Ashby + Rod Mitchell\"]\n",
        "# actors_expanded = [\"Dougray Scott + Judy + Slay+Prepare the Animal for Meat + Vigil + Crime + Irena's Vow\", \"Nathaniel Parker + Girls Hugging Their Fathers + The Doll Factory + The Velveteen Rabbit + T.I.M. + Up on the Roof\", \"Charlie Hunnam + Rebel Moon - Part Two: The Scargiver + Rebel Moon: Part One - A Child of Fire + Shantaram + Last Looks + The Gentlemen\", \"Michael Sheen + The Price of Admission + Heart of Darkness + A Very Royal Scandal + The Way + Good Omens\"]"
      ],
      "metadata": {
        "id": "ektO3dz6xyTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Movie expanded queries:\")\n",
        "for expanded_movie in movies_expanded:\n",
        "  print(expanded_movie)\n",
        "\n",
        "\n",
        "print(\"\\nActor expanded queries:\")\n",
        "for expanded_actor in actors_expanded:\n",
        "  print(expanded_actor)"
      ],
      "metadata": {
        "id": "BrgaSenWzbjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Processing\n",
        "\n",
        "Process images for original queries."
      ],
      "metadata": {
        "id": "YM1C0UK7prFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "pip install icrawler"
      ],
      "metadata": {
        "id": "hr5gN104qz-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/python\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "def remove_directory(directory):\n",
        "  # Try to remove the tree; if it fails, throw an error using try...except.\n",
        "  try:\n",
        "      shutil.rmtree(directory)\n",
        "  except OSError as e:\n",
        "      print(\"Error: %s - %s.\" % (e.filename, e.strerror))"
      ],
      "metadata": {
        "id": "nB1JTk9OyBKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove directory if they exist and create new directory\n",
        "remove_directory(\"movie\")\n",
        "remove_directory(\"actor\")\n",
        "remove_directory(\"movie_final\")\n",
        "remove_directory(\"actor_final\")"
      ],
      "metadata": {
        "id": "w-b7vL_OyUWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHBEU2_74BdL"
      },
      "outputs": [],
      "source": [
        "from icrawler.builtin import GoogleImageCrawler\n",
        "from IPython.display import Image, display\n",
        "import os\n",
        "\n",
        "def crawl_images(keyword, searchType, max_num_per_query):\n",
        "    folder_path = searchType + '/' + keyword + '/'\n",
        "\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "\n",
        "    # Download images\n",
        "    # Setup a directory for images\n",
        "    query = f\"{keyword} {searchType} images\"\n",
        "    google_crawler = GoogleImageCrawler(storage={'root_dir': folder_path})\n",
        "    google_crawler.crawl(keyword=query, max_num=max_num_per_query)\n",
        "    print(query)\n",
        "\n",
        "    return folder_path\n",
        "\n",
        "def display_images(folder_path):\n",
        "  # Display images, filtering for common image file extensions\n",
        "  for image_file in os.listdir(folder_path):\n",
        "    if image_file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
        "        display(Image(filename=os.path.join(folder_path, image_file)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use icrawler to retrieve images for query\n",
        "\n"
      ],
      "metadata": {
        "id": "e6jIqI6yn2BT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGlj-N4c5PV0"
      },
      "outputs": [],
      "source": [
        "# to store the folder path\n",
        "folder_path = []\n",
        "\n",
        "max_num_per_query = 10\n",
        "\n",
        "# get random movies\n",
        "movies = selected_movies\n",
        "actors = selected_crew_members\n",
        "\n",
        "# store the images for the movies\n",
        "for movie in movies:\n",
        "  folder_path.append(crawl_images(movie, \"movie\", max_num_per_query))\n",
        "\n",
        "# store the images for the actors\n",
        "for actor in actors:\n",
        "  folder_path.append(crawl_images(actor, \"actor\", max_num_per_query))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process images for expanded queries."
      ],
      "metadata": {
        "id": "sujyvIsAt1M3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "expanded_movies = movies_expanded\n",
        "expanded_actors = actors_expanded\n",
        "\n",
        "# store the images for the movies\n",
        "for movie in expanded_movies:\n",
        "  folder_path.append(crawl_images(movie, \"movie_final\", max_num_per_query))\n",
        "\n",
        "for actor in expanded_actors:\n",
        "  folder_path.append(crawl_images(actor, \"actors_final\", max_num_per_query))"
      ],
      "metadata": {
        "id": "EdQYQgKKykUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount drive to store images."
      ],
      "metadata": {
        "id": "pOZcbpM2rayF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount it\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# copy it there\n",
        "!cp -r /content/movie /content/drive/MyDrive\n",
        "!cp -r /content/actor /content/drive/MyDrive\n",
        "!cp -r /content/movie_final /content/drive/MyDrive\n",
        "!cp -r /content/actors_final /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "a57MqkyS0LWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display Data"
      ],
      "metadata": {
        "id": "QhQQkj1nuk6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "import urllib.request\n",
        "\n",
        "# Function to display the actor or director data in a nicely formatted way\n",
        "def display_person_data(person_data):\n",
        "    # Retrieve and display the headshot\n",
        "    headshot_url = person_data.get('headshot', '')\n",
        "    if headshot_url:\n",
        "        try:\n",
        "            # Check if the headshot URL is accessible\n",
        "            urllib.request.urlopen(headshot_url)\n",
        "            display(HTML(f'<img src=\"{headshot_url}\" alt=\"Headshot\" style=\"width:150px;height:auto;\">'))\n",
        "        except:\n",
        "            display(HTML('<p>Headshot not available.</p>'))\n",
        "\n",
        "    # Display name\n",
        "    display(HTML(f'<h2>{person_data[\"name\"]}</h2>'))\n",
        "\n",
        "    # Display filmography\n",
        "    for role in person_data['filmography']:\n",
        "        display(HTML(f'<h3>{role.title()}:</h3>'))\n",
        "        role_html = '<ul>'\n",
        "        for movie in person_data['filmography'][role]:\n",
        "            role_html += f'<li>{movie}</li>'\n",
        "        role_html += '</ul>'\n",
        "        display(HTML(role_html))\n",
        "\n",
        "def display_movie_data(movie_data):\n",
        "    # Display movie title and year\n",
        "    title = movie_data.get('Title', 'Unknown Title')\n",
        "    year = movie_data.get('Year', 'Unknown Year')\n",
        "    display(HTML(f'<h2>{title} ({year})</h2>'))\n",
        "\n",
        "    # Display other movie details\n",
        "    details_html = '<ul>'\n",
        "    for key in ['Director', 'Cast', 'Genre', 'Runtime', 'Plot']:\n",
        "        if key in movie_data:\n",
        "            value = movie_data[key]\n",
        "            if isinstance(value, list):\n",
        "                value = ', '.join(value)  # Convert list to string\n",
        "            details_html += f'<li><b>{key}:</b> {value}</li>'\n",
        "    details_html += '</ul>'\n",
        "    display(HTML(details_html))\n"
      ],
      "metadata": {
        "id": "lZbhQZuyujvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GIF retrieval\n",
        "We are using the Tenor's gif retrieval api."
      ],
      "metadata": {
        "id": "uU-lnb0e6Qce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To call the third party APIs\n",
        "import requests"
      ],
      "metadata": {
        "id": "aLJM80GfwxnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print dict\n",
        "def print_dict(dict):\n",
        "  # Printing each key-value pair separately\n",
        "  for key, value in dict.items():\n",
        "    print(key, \":\", value)"
      ],
      "metadata": {
        "id": "bv8Ja-WHw4Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tenor_api_url = \"https://g.tenor.com/v1/search\"\n",
        "\n",
        "def get_gifs(payload):\n",
        "  r = requests.get(tenor_api_url, params=payload)\n",
        "  json_response = r.json()\n",
        "  # Initialize an empty list to store gif URLs\n",
        "  gif_urls = []\n",
        "\n",
        "  # Extract 'url' attribute inside 'gif' and store them in the list\n",
        "  for result in json_response.get('results', []):\n",
        "    for media_item in result.get('media', []):\n",
        "        gif_url = media_item.get('gif', {}).get('url')\n",
        "        if gif_url:\n",
        "            gif_urls.append(gif_url)\n",
        "  return gif_urls"
      ],
      "metadata": {
        "id": "22psDkz46PlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve gif data for normal data\n",
        "limit = 5\n",
        "tenor_api_key = \"LIVDSRZULELA\"\n",
        "\n",
        "movie_gif_results = {}\n",
        "crew_gif_results = {}\n",
        "\n",
        "# get the gifs for the movies\n",
        "for movie in selected_movies:\n",
        "  response = get_gifs({\"q\":movie, \"limit\": limit, \"key\": tenor_api_key})\n",
        "  movie_gif_results[movie] = response\n",
        "\n",
        "for crew_member in selected_crew_members:\n",
        "  response = get_gifs({\"q\":crew_member, \"limit\": limit, \"key\": tenor_api_key})\n",
        "  crew_gif_results[crew_member] = response\n",
        "\n",
        "print(\"Movie Gif results:\\n\")\n",
        "print_dict(movie_gif_results)\n",
        "\n",
        "print(\"\\n\\nCrew Gif results:\\n\")\n",
        "print_dict(crew_gif_results)"
      ],
      "metadata": {
        "id": "RkjoKnMF6hh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve gif data for expanded data\n",
        "movie_expanded_gif_results = {}\n",
        "crew_expanded_gif_results = {}\n",
        "\n",
        "# get the gifs for the movies\n",
        "for movie in movies_expanded:\n",
        "  response = get_gifs({\"q\":movie, \"limit\": limit, \"key\": tenor_api_key})\n",
        "  # Split the text by the \"+\" sign and get the first part\n",
        "  movie_name = movie.split('+')[0].strip()\n",
        "  movie_expanded_gif_results[movie_name] = response\n",
        "\n",
        "for crew_member in actors_expanded:\n",
        "  response = get_gifs({\"q\":crew_member, \"limit\": limit, \"key\": tenor_api_key})\n",
        "  # Split the text by the \"+\" sign and get the first part\n",
        "  crew_name = crew_member.split('+')[0].strip()\n",
        "  crew_expanded_gif_results[crew_name] = response\n",
        "\n",
        "print(\"Movie Gif results:\\n\")\n",
        "print_dict(movie_expanded_gif_results)\n",
        "\n",
        "print(\"\\n\\nCrew Gif results:\\n\")\n",
        "print_dict(crew_expanded_gif_results)"
      ],
      "metadata": {
        "id": "eRgAkakmuX3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Youtube Search API"
      ],
      "metadata": {
        "id": "fDpjqqTrmJph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "youtube_api_url = \"https://youtube.googleapis.com/youtube/v3/search\"\n",
        "\n",
        "def search_videos(payload):\n",
        "  r = requests.get(youtube_api_url, params=payload)\n",
        "  json_response = r.json();\n",
        "  # Initialize an empty list to store videoIds\n",
        "  video_ids = []\n",
        "\n",
        "  # Extract videoIds from the items in the JSON response\n",
        "  for item in json_response.get('items', []):\n",
        "      video_id = item.get('id', {}).get('videoId')\n",
        "      if video_id:\n",
        "          video_ids.append(video_id)\n",
        "\n",
        "  return video_ids"
      ],
      "metadata": {
        "id": "Q9gohLAymMQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "limit = 5\n",
        "youtube_api_key = \"AIzaSyARZnjRAYi4-tHYV_rOetFJOQ2mwC_ieoA\" ## [Replace with your API key]\n",
        "\n",
        "movie_video_results = {}\n",
        "crew_video_results = {}\n",
        "\n",
        "# get the videos for the movies\n",
        "for movie in selected_movies:\n",
        "  response = search_videos({\"q\":movie, \"maxResults\": limit, \"key\": youtube_api_key})\n",
        "  movie_video_results[movie] = response\n",
        "\n",
        "for crew_member in selected_crew_members:\n",
        "  response = search_videos({\"q\":crew_member, \"maxResults\": limit, \"key\": youtube_api_key})\n",
        "  crew_video_results[crew_member] = response\n",
        "\n",
        "print(\"Movie video results:\\n\")\n",
        "print_dict(movie_video_results)\n",
        "\n",
        "print(\"\\n\\nCrew video results:\\n\")\n",
        "print_dict(crew_video_results)\n"
      ],
      "metadata": {
        "id": "mdPjGFg4m87C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_expanded_video_results = {}\n",
        "crew_expanded_video_results = {}\n",
        "\n",
        "# get the videos for the movies\n",
        "for movie in movies_expanded:\n",
        "  response = search_videos({\"q\":movie, \"maxResults\": limit, \"key\": youtube_api_key})\n",
        "  movie_expanded_video_results[movie_name] = response\n",
        "\n",
        "for crew_member in actors_expanded:\n",
        "  response = search_videos({\"q\":crew_member, \"maxResults\": limit, \"key\": youtube_api_key})\n",
        "  crew_expanded_video_results[crew_member] = response\n",
        "\n",
        "print(\"Movie video results:\\n\")\n",
        "print_dict(movie_expanded_video_results)\n",
        "\n",
        "print(\"\\n\\nCrew video results:\\n\")\n",
        "print_dict(crew_expanded_video_results)"
      ],
      "metadata": {
        "id": "gOSQ7QbuwMGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## final report queries\n",
        "query_1 = [\"Scrooge: A Christmas Carol\", \"Scrooge: A Christmas Carol + Stephen Donnelly + Luke Evans + Scrooge + Olivia Colman + Past + Jessie Buckley + Isabel Fezziwig\"]\n",
        "\n",
        "query_2 = [\"The Tower\", \"The Tower + Gemma Whelan + DS Sarah Collins + Emmett J Scanlan + Inspector Kieran Shaw + Tahirah Sharif + PC Lizzie Adama\"]\n",
        "\n",
        "query_3 = [\"Love Affair\", \" Love Affair + Warren Beatty + Mike Gambril + Annette Bening + Terry McKay + Katharine Hepburn + Ginny\"]\n",
        "\n",
        "# video\n",
        "def retrieve_video_results(queries):\n",
        "  query_result = {}\n",
        "  for query in queries:\n",
        "    response = search_videos({\"q\":query, \"maxResults\": limit, \"key\": youtube_api_key})\n",
        "    query_result[query] = response\n",
        "  return query_result\n",
        "\n",
        "query_1_result = retrieve_video_results(query_1)\n",
        "query_2_result = retrieve_video_results(query_2)\n",
        "query_3_result = retrieve_video_results(query_3)\n",
        "\n",
        "print(query_1_result)\n",
        "print(query_2_result)\n",
        "print(query_3_result)"
      ],
      "metadata": {
        "id": "AJFCGSbm1aCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Play retrieved videos"
      ],
      "metadata": {
        "id": "W8k3zVRkvKgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pytube"
      ],
      "metadata": {
        "id": "gQeCNk1kvO3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "\n",
        "# Enter 'VIDEO_ID' with the actual YouTube video ID\n",
        "video_id = input(\"Enter Video_id: \")\n",
        "\n",
        "# Display the YouTube video\n",
        "YouTubeVideo(video_id)"
      ],
      "metadata": {
        "id": "BeojwiryvRtp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}